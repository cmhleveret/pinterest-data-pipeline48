{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54b828e2-a3c6-4841-98de-77be3d5f42dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, lower, concat, lit, to_timestamp, col\n",
    "\n",
    "# cleaned_df = example_df.replace({'User Info Error': None}, subset=['Status'])\n",
    "\n",
    "class UserDataCleaning():\n",
    "    def __init__(self):\n",
    "        print(\"UserData Cleaning init\")\n",
    "\n",
    "    def concat_name(self, df):\n",
    "        df = df.withColumn('user_name', concat(df['first_name'], lit(' '), df['last_name']))\n",
    "        return df\n",
    "    \n",
    "    def drop_first_last_name(self, df):\n",
    "        df = df.drop('first_name', 'last_name')\n",
    "        return df\n",
    "    \n",
    "    def cast_timestamp(self, df):\n",
    "        df = df.withColumn(\"date_joined\", to_timestamp(col(\"date_joined\"), 'yyyy-MM-dd\\'T\\'HH:mm:ss'))\n",
    "        df = df.withColumn(\"date_joined\", col(\"date_joined\").cast(\"timestamp\"))\n",
    "        # df = df.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), 'yyyy-MM-dd\\'T\\'HH:mm:ss'))\n",
    "        return df\n",
    "    \n",
    "    def reorder_columns(self, df):\n",
    "        df = df.select(\n",
    "            \"ind\",\n",
    "            \"user_name\",\n",
    "            \"age\",\n",
    "            \"date_joined\",\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "\n",
    "# Replace empty entries and entries with no relevant data in each column with Nones\n",
    "data_cleaning_instance = UserDataCleaning()\n",
    "# Create a new column user_name that concatenates the information found in the first_name and last_name columns\n",
    "cleaned_data_concat_name = data_cleaning_instance.concat_name(user_df)\n",
    "# Drop the first_name and last_name columns from the DataFrame\n",
    "cleaned_data_drop_first_last_name = data_cleaning_instance.drop_first_last_name(cleaned_data_concat_name)\n",
    "# Convert the date_joined column from a string to a timestamp data type\n",
    "cleaned_data_cast_timestamp = data_cleaning_instance.cast_timestamp(cleaned_data_drop_first_last_name)\n",
    "# Reorder the DataFrame columns to have the following column order: ind, user_name, age, date_joined\n",
    "cleaned_data_reordered_cols = data_cleaning_instance.reorder_columns(cleaned_data_cast_timestamp)\n",
    "\n",
    "cleaned_user_data = cleaned_data_reordered_cols\n",
    "\n",
    "# display(cleaned_data_reordered_cols)\n",
    "# display(cleaned_data_cols_to_int.dtypes)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clean-streaming-data-user",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
