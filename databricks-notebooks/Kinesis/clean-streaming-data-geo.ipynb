{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78b11e85-6279-4cc7-a67c-63173c674522",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, lower, array, to_timestamp, col\n",
    "\n",
    "# cleaned_df = example_df.replace({'User Info Error': None}, subset=['Status'])\n",
    "\n",
    "class GeoDataCleaning():\n",
    "    def __init__(self):\n",
    "        print(\"GeoData Cleaning init\")\n",
    "    \n",
    "    def create_coordinates_array_col(self, df):\n",
    "       df = df.withColumn('coordinates', array(df['latitude'], df['longitude']))\n",
    "       return df\n",
    "   \n",
    "    def drop_lat_long(self, df):\n",
    "        df = df.drop('latitude', 'longitude')\n",
    "        return df\n",
    "    \n",
    "    def cast_timestamp(self, df):\n",
    "        df = df.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), 'yyyy-MM-dd\\'T\\'HH:mm:ss'))\n",
    "        df = df.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    "        # df = df.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), 'yyyy-MM-dd\\'T\\'HH:mm:ss'))\n",
    "        return df\n",
    "    \n",
    "    def reorder_columns(self, df):\n",
    "        df = df.select(\n",
    "            \"ind\",\n",
    "            \"country\",\n",
    "            \"coordinates\",\n",
    "            \"timestamp\",\n",
    "        )\n",
    "        return df\n",
    "\n",
    "# Replace empty entries and entries with no relevant data in each column with Nones\n",
    "data_cleaning_instance = GeoDataCleaning()\n",
    "# Create a new column coordinates that contains an array based on the latitude and longitude columns\n",
    "cleaned_data_coordinate_col = data_cleaning_instance.create_coordinates_array_col(geo_df)\n",
    "# Drop the latitude and longitude columns from the DataFrame\n",
    "cleaned_data_drop_lat_long = data_cleaning_instance.drop_lat_long(cleaned_data_coordinate_col)\n",
    "# Convert the timestamp column from a string to a timestamp data type\n",
    "cleaned_data_cast_timestamp = data_cleaning_instance.cast_timestamp(cleaned_data_drop_lat_long)\n",
    "# Reorder the DataFrame columns to have the following column order: ind, country, coordinates, timestamp\n",
    "cleaned_data_reordered_cols = data_cleaning_instance.reorder_columns(cleaned_data_cast_timestamp)\n",
    "\n",
    "cleaned_geo_data = cleaned_data_reordered_cols\n",
    "\n",
    "display(cleaned_data_reordered_cols)\n",
    "# display(cleaned_data_cols_to_int.dtypes)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clean-streaming-data-geo",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
